---
title: Iterating on `parallel_scheduler`
document: P3804R0
date: today
author:
    - name: Lucian Radu Teodorescu (Garmin)
      email: <lucteo@lucteo.ro>
    - name: Ruslan Arutyunyan (Intel)
      email: <ruslan.arutyunyan@intel.com>
audience:
    - SG1, LEWG
---

<style>
@media screen {
    #TOC {
        position: fixed;
        width: min(25%, 30em);
        height: 100%;
        left: 0;
        top: 0;
        overflow-y: scroll;
        padding-left: 1em;
        padding-right: 1em;
        text-align: left;
        a {
            font-size: 100%;
        }
    }
    body {
        padding-left: min(26%, 32em);
    }
}
</style>

# Abstract # {- .unlisted}

Although `parallel_scheduler` [@P2079R10] had a long time in the baking, getting it adopted in Sofia 2025 still left the impression that some of the fine details were not sufficiently discussed. This paper proposes to iterate over some of these aspects, aiming at getting the best possible outcome from `parallel_scheduler`.

# Introduction #

This paper tries to address the following concerns:

* Minor design tweaks:
  1. `receiver_proxy::try_query` could possibly be const-qualified.
  2. `receiver_proxy` does not need a virtual destructor as the object is never destroyed polymorphically.
  3. `receiver_proxy::try_query` requires `inplace_stop_token` and doesn't accept an arbitrary stop token.
  4. The list of properties supported by `receiver_proxy::try_query` is implementation-defined.
* Design concerns with larger impact:
  5. `receiver_proxy::try_query` currently requires the list of supported queries to be defined.
* Naming:
  6. `system_context_replaceability` is not a good name to use for the namespace in which the replaceability APIs lie.
* Wording:
  7. The wording around a customizations of `bulk_unchunked`/`bulk_chunked` for `parallel_scheduler` isn't precise enough.

# Discussions #

## `receiver_proxy::try_query` could possibly be const-qualified

Currently the specification defines `try_query` as:
```cpp
template<class P, @_class-type_@ Query>
optional<P> try_query(Query q) noexcept;
```

This is not marked as `const`, but there is no good reason why we couldn't mark it as such.
This paper proposes a change to mark this function as `const`.

## `receiver_proxy` does not need a virtual destructor

The code that destroys instances of `receiver_proxy` knows the actual type of the object, so the objects of type `receiver_proxy` don't need to be polymorphically destroyed.
This paper proposes to remove the virtual destructor.

## `receiver_proxy::try_query` requires `inplace_stop_token` and doesnâ€™t accept an arbitrary stop token

The specification of `parallel_scheduler::try_query` [@P2079R10] is too restrictive with respect to querying stop tokens.
The wording states ([exec.sysctxrepl.query]):

---

```cpp
template <class P, @_class-type_@ Query>
optional<P> try_query(Query q) noexcept;
```

[5]{.pnum} *Mandates*: `P` is a cv-unqualified non-array object type.

[6]{.pnum} *Returns*: Let `env` be the environment of the receiver represented by `*this`.
If:

- [6.1]{.pnum} `Query` is not a member of an implementation-defined set of supported queries; or
- [6.2]{.pnum} `P` is not a member of an implementation-defined set of supported result types for `Query`; or
- [6.3]{.pnum} the expression `q(env)` is not well-formed or does not have type _`cv`_ `P`,

then returns `nullopt`. Otherwise, returns `q(env)`.

[7]{.pnum} *Remarks*: `get_stop_token_t` is in the implementation-defined set of supported queries, and `inplace_stop_token` is a member of the implementation-defined set of supported result types for `get_stop_token_t`.

---

This implies that, if `q(get_stop_token_t)` returns `std::stop_token`, then `try_query(get_stop_token_t)` returns `nullopt`.
More generally, if `q(get_stop_token_t)` returns a type that models `stoppable_token`, other than `inplace_stop_token`, then `try_query(get_stop_token_t)` returns `nullopt`.
There is no portable way for the backend to check the stop token of the receiver.

This paper proposes an extension of the above schema to allow the possibility of using stop tokens other than `inplace_stop_token`.
If `q(env)` has the type _`cv`_  `T`, and there is an implementation defined mapping from objects of type `T` to objects of type `P`, then `try_query<P>(q)` is allowed to return non-null objects.

We recommend the implementations to support such mappings between any stop token to `inplace_stop_token`.
This would essentially make the frontend register a stop callback to the token from the environment and transform the stop request into a stop request to a temporary `inplace_stop_token`.

Please note that this mechanism is useful for other property types, not just stop tokens.

We also considered an alternative design in which we add a `request_stop` member-function to `parallel_scheduler_backend`.
This method would increase the API surface, and render the property-querying mechanism useless.
We considered this solution to be less flexible, as, on the long run, it would lead to an overly-complex API for replaceability.

## The list of properties supported by `receiver_proxy::try_query` is implementation-defined

When [@P2079R10] defines the possibilities for the backend to query the properties of the final receiver it specifies that the list of properties (both property types and query types) are implementation-defined.
Instead, the proposal could have defined a fixed list of properties to be supported when replacing the backend.

That seems to be a limiting factor as we would want to support two use-cases:

1. Implementers might want to add additional properties to be queried
1. Implementers might not want to implement all the properties

A good example for the first case is a vendor adding support for thread priorities.
With the existing proposal, this can be done in a compliant manner.

The second case involves implementors opting out of certain properties.
Let us assume that we standardize a mechanism to query thread priorities from the receiver.
But, this may not make much difference on certain platforms, thus the implementors shall be able to opt out of supporting this query.
Supporting a query typically has a small cost associated with it, so it makes sense to allow opting out of this cost if it doesn't make sense for the targeted platform.

Even with stop token property that is specified by [@P2079R10], it may not always make sense to support cancellation on the backend.
The frontend can implement cancellation without passing this information to the backend.

Thus, the authors believe that the current option of making the list of properties (and query types) is the right choice for the users and no changes are needed here.

## `receiver_proxy::try_query` currently requires the list of supported queries to be defined

One workflow that some of C++ have is to have separate compilations of their libraries.
Two libraries, A and B can be compiled separately, sometimes with different versions of the compiler, sometimes even with different compilers (provided that the ABI match).
This feature cannot break this flow.

For practical reasons, we can consider the backend of `parallel_scheduler` as yet another library C that can be compiled separately from the rest of the program.
The backend may be compiled with different flag and with a different compiler than the rest of the modules (again, if the ABI matches).
That is, there is a complete separation between the frontend (library implementing `parallel_scheduler`) and the backend (user provided implementation of `parallel_scheduler_backend`).

This separation makes it impossible a completely extensible list of properties that can be dynamically agreed between the frontend and the backend.
Let us walk the implications of this with two examples.

Let's assume that frontend defines a new property `friendliness`; maybe the program was compiled with a newer version of the standard that defined this property, while the backend is compiled with C++26.
How would the backend implementation use this new property if it doesn't even know it exists?
It cannot.

Looking from the opposite direction, let's now assume that the backend is compiled with a newer version of the standard that knows about the `firendliness` property, and that the frontend is compiled with C++26 which doesn't know about this property.
The backend can try to query on the existence of this property, and we hope that the query needs to be actually fulfilled in the frontend.

In this case, the discussion can be slightly more complicated.
While the frontend might not know about `friendliness`, the environment in which the sender created by `parallel_scheduler` might now about this (for example, the user code is built for a newer version of C++ than the standard library it uses).
Looking at the versions, the triad user code, `parallel_scheduler` and backend looks like: new-old-new.
While, theoretically we can solve the problem making the query work between the frontend and the backend (complicated, but we can), we need to solve the problem for the fronted querying the environment for a property `friendliness` that it does not know about (e.g., the same problem as before).

The frontend can only query the environment by having some compile-time knowledge.
Thus, the list of properties that frontend supports need to be known at compile-time.
This aligns with the existing design in which both the frontend and the backend need to know at compile-time the list of properties that they support.

To put it in a different perspective, the querying mechanism for senders/receivers is compile-time, and we cannot use it fully dynamic over run-time resilience boundaries.

The authors don't see any changes in this area that would benefit the users.

## `system_context_replaceability` is not a good name to use for the namespace in which the replaceability APIs lie

Previously, `parallel_scheduler` was called `system_scheduler`, and was part of `system_context`.
In that sense, the name `system_context_replaceability` made sense; it was the namespace in which we put things related to replacing default implementation around `system_context`.
But now, we ended up with a different name, so the question is whether `system_context_replaceability` still makes sense.

There are people who's answer would be no.
In that case, we might rename the namespace to something like `parallel_scheduler_replaceability`.

But, there are also arguments for keeping the current name.
We also envision having different types of schedulers.
We were previously taking about a `main_scheduler` to be used on systems that have only one thread, or in which the main thread needs special treatment.
We also had brief discussions about the need of `io_scheduler` (or `elastic_parallel_scheduler`) and `priority_scheduler` (to create threads with different priorities).

There is a high chance that we would add new system-wide schedulers in the future.
But, if that is the case, and we want their backends to be replaceable, should we create completely different namespaces for them?
Or should we reuse the abstractions that we already have?

Probably, a good answer would be that we want to reuse the same namespace.
In this context, the name `system_context_replaceability` makes sense.
Especially since the work `context` appears in the name, not the word `scheduler`.

The authors don't have a strong preference, and would like this to be discussed in LEWG.
The following table shows a few options:

| Proposal | Notes            |
| -------- | ---------------- |
| `system_context_replaceability` | Status quo. Allows replacing other backend in the future |
| `parallel_scheduler_replaceability` | Better matches the new name |
| `scheduler_replaceability` | Variation |
| `scheduler_backend_replaceability` | Variation |
| `parallel_scheduler_backend_replaceability` | Variation |

## The wording around a customizations of `bulk_unchunked`/`bulk_chunked` for `parallel_scheduler` isnâ€™t precise enough

The wording in [@P2079R10] mandated that we want customizations for `bulk_unchunked`/`bulk_chunked`, but it did not describe the details.
Actually, this discussion was completely missing from the design section too.
The proof of concept implementation used the early customization mechanism, and part of the authors assumed that was always the case, but the paper doesn't mention anything about it.
This needs to be fixed.

There are two main methods in which we can customize the `bulk` algorithms:

- early customization (based just on the previous sender, before connecting the resulting sender to a receiver);
- late customization (also taking into consideration the environment of the receiver).

<!-- The following table shows a few examples and whether they would work with early or late customizations:

<table border="1">
<style>
    th {
        border-bottom: 3px double black; /* Double underline */
    }
</style>
<tr><th>Example</th><th>Early?</th><th>Late?</th><th>Notes</th></tr>

<tr>
<td>
```c++
task<void> example1() {
Â  co_await bulk(schedule(get_parallel_scheduler()), par, 1'000'000, func);
}
```
</td>
<td>yes</td><td>no</td><td>Scheduler is taken from previous sender.</td>
</tr>

<tr>
<td>
```c++
task<void, parallel_env> example2() {
Â  co_await bulk(just(), par, 1'000'000, func);
}
```
</td>
<td>no</td><td>yes</td><td>Taking the scheduler from the environment of the receiver.</td>
</tr>

<tr>
<td>
```c++
task<void, parallel_env> example3() {
  parallel_scheduler sched = co_await read_env(get_scheduler);
Â  co_await bulk(schedule(sched), par, 1'000'000, func);
}
```
</td>
<td>yes</td><td>yes</td><td>Allows early-customization; no extra `schedule` operation is actually executed.</td>
</tr>

<tr>
<td>
```c++
task<void, parallel_env> example4() {
  parallel_scheduler sched = co_await read_env(get_scheduler);
  sender auto prev = schedule(sched) | then(something);
Â  co_await bulk(std::move(prev), par, 1'000'000, func);
}
```
</td>
<td>yes</td><td>yes</td><td>Early customization works even if the previous sender isn't directly a `schedule`.</td>
</tr>

<tr>
<td>
```c++
task<void, parallel_env> example5() {
  parallel_scheduler sched = co_await read_env(get_scheduler);
Â  co_await bulk(pseudo_schedule(sched), par, 1'000'000, func);
}
```
</td>
<td>yes</td><td>yes</td><td>Early customizations with custom scheduling.</td>
</tr>

</table> -->

The early customization depends only on the previous sender passed to the `bulk` algorithms.
If this has a domain that is equal to the domain of `parallel_scheduler` then early customization kicks in.
On the other hand, late customization also takes into consideration the domain coming from the receiver's environment.

The `bulk` algorithms are not expected to depend on the receiver's environment, so making it late customizable will be a surprise to the users.
The user expects that `bulk` is run on the scheduler of its given predecessor.

If we implement early customization for `bulk` algorithms, the following example would not take advantage of parallel scheduler:

```c++
task<void, parallel_env> calls_serial_bulk() {
Â  co_await bulk(just(), par, 1'000'000, func);
}
```

This is fine, as it appears immediately to the user that `parallel_scheduler` was not used in `bulk`s invocation (even if `parallel_scheduler` can be obtained from the receiver's environment).
To ensure that the `bulk` is run on `parallel_scheduler`, the user can do the following:

```c++
task<void, parallel_env> calls_parallel_bulk() {
  parallel_scheduler sched = co_await read_env(get_scheduler);
Â  co_await bulk(schedule(sched), par, 1'000'000, func);
}
```

This makes it explicit that we want to use the scheduler from the environment.
It is typically a good idea to demand the user to be explicit in such cases, and avoid guessing.

If the user somehow gets this wrong, the performance difference between running the `bulk` algorithm on `parallel_scheduler` and running it serially should be immediately noticeable, and the user can fix the mistake.
But, if we wanted to have late customization, and the user gets it wrong, jumping from one execution agent to another might not be immediately noticeable, making the mistake harder to find.

In addition of specifying how the customization needs to be implemented, the wording also misses specification on how the execution policies passed to `bulk` algorithms are handled.

This paper advocates for using early customization of `bulk` algorithms for `parallel_scheduler`.


# Proposed wording #

In section Parallel scheduler [exec.par.scheduler], apply the following changes:

::: rm

[7]{.pnum} A _bulk chunked proxy for `rcvr` with callable `f` and arguments `args`_ is a proxy `r` for `rcvr` with base `system_context_replaceability::bulk_item_receiver_proxy` such that`r.execute(i, j)` for indices `i` and `j` has effects equivalent to `f(i, j, args...)`.

[8]{.pnum} A _bulk unchunked proxy for `rcvr` with callable `f` and arguments `args`_ is a proxy `r` for `rcvr` with base `system_context_replaceability::bulk_item_receiver_proxy` such that `r.execute(i, i+1)` for index `i` has effects equivalent to `f(i, args...)`.

:::

[9]{.pnum} Let `b` be <i>`BACKEND-OF`</i>`(sch)`, let `sndr` be the object returned by `schedule(sch)`, and let `rcvr` be a receiver.
  If `rcvr` is connected to `sndr` and the resulting operation state is started, then:
    - If `sndr` completes successfully, then `b.schedule(r, s)` is called, where:
      - `r` is a proxy for `rcvr` with base `system_context_replaceability::receiver_proxy`; and
      - `s` is a preallocated backend storage for `r`.
  - All other completion operations are forwarded unchanged.

::: rm

[10]{.pnum} `parallel_scheduler` provides a customized implementation of `bulk_chunked` algorithm ([exec.bulk]{.sref}).
  If a receiver `rcvr` is connected to the sender returned by `bulk_chunked(sndr, pol, shape, f)` and the resulting operation state is started, then:

- [10.1]{.pnum} If `sndr` completes with values `vals`, let `args` be a pack of lvalue subexpressions designating `vals`, then `b.schedule_bulk_chunked(shape, r, s)` is called, where:
  - [10.1.1]{.pnum} `r` is a bulk chunked proxy for `rcvr` with callable `f` and arguments `args`; and
  - [10.1.2]{.pnum} `s` is a preallocated backend storage for `r`.
- [10.2]{.pnum} All other completion operations are forwarded unchanged.

[Customizing the behavior of `bulk_chunked` affects the default implementation of `bulk`]{.note}.

[11]{.pnum} `parallel_scheduler` provides a customized implementation of `bulk_unchunked` algorithm \[exec.bulk].
  If a receiver `rcvr` is connected to the sender returned by `bulk_unchunked(sndr, pol, shape, f)` and the resulting operation state is started, then:

- [11.1]{.pnum} If `sndr` completes with values `vals`, let `args` be a pack of lvalue subexpressions designating `vals`, then `b.schedule_bulk_unchunked(shape, r, s)` is called, where:
  - [11.1.1]{.pnum} `r` is a bulk unchunked proxy for `rcvr` with callable `f` and arguments `args`; and
  - [11.1.2]{.pnum} `s` is a preallocated backend storage for `r`.
- [11.2]{.pnum} All other completion operations are forwarded unchanged.

:::

::: add

[?]{.pnum} Let _`TAG-OF`_`(sndr)` be the tag type of sender `sndr`.
If _`TAG-OF`_`(sndr)` is `bulk_chunked_t` or `bulk_unchunked_t`, let _`POLICY-OF`_`(sndr)` be the execution policy used to construct the sender and let _`SHAPE-OF`_`(sndr)` be the shape used to construct the sender.
Also, let _`PARALLELIZABLE`_`(pol)` for an execution policy `pol` be `true` if `pol` is `par` or `par_unseq`, and `false` otherwise.

[10]{.pnum} The expression `get_domain(sch)` returns an expression of exposition-only type _`parallel-scheduler-domain`_, that is equivalent with:
```c++
struct @_parallel-scheduler-domain_@ {
    template<sender Sndr, queryable... Env>
        requires (sizeof...(Env) <= 1)
      static constexpr sender decltype(auto) transform_sender(Sndr&& sndr, const Env&... env)
        noexcept;
};
```

```
template<sender Sndr, queryable... Env>
  requires (sizeof...(Env) <= 1)
constexpr sender decltype(auto) @_parallel-scheduler-domain_@::transform_sender(Sndr&& sndr, const Env&... env)
  noexcept;
```

- [11]{.pnum} _Returns_:
  - [11.1]{.pnum} `sndr`, if `same_as<auto(get_completion_scheduler<set_value_t>(get_env(sndr))), parallel_scheduler>` is `false` or if if _`TAG-OF`_`(sndr)` is not `bulk_chunked_t` nor `bulk_unchunked_t`.

  - [11.2]{.pnum} Otherwise, it returns a sender that, when a receiver `rcvr` is connected to it, and the resulting operation state is started, then:

    - [11.2.1]{.pnum} If `sndr` completes with values `vals`, let `args` be a pack of lvalue subexpressions designating `vals`, let `parallelize` be `@_PARALLELIZABLE_@(@_POLICY-OF_@(sndr))`, and let `shape` be `@_SHAPE-OF_@(sndr)`, then:

      - [11.2.1.1]{.pnum} If _`TAG-OF`_`(sndr)` is `bulk_chunked_t`, then `b.schedule_bulk_chunked(parallelize ? shape : 1, r, s)` is called, where:

          - [11.2.1.1.1]{.pnum} `r` is a proxy for `rcvr` with base `system_context_replaceability::bulk_item_receiver_proxy` such that `r.execute(i, j)` for indices `i` and `j` has effects equivalent to `f(i, j, args...)` if `parallelize` is `true` and `f(0, shape, args...)` otherwise; and
          - [11.2.1.1.2]{.pnum} `s` is a preallocated backend storage for `r`.

      - [11.2.1.2]{.pnum} If _`TAG-OF`_`(sndr)` is `bulk_unchunked_t`, then `b.schedule_bulk_unchunked(parallelize ? shape : 1, r, s)` is called, where:

          - [11.2.1.2.1]{.pnum} `r` is a proxy for `rcvr` with base `system_context_replaceability::bulk_item_receiver_proxy` such that `r.execute(i, i+1)` for index `i` has effects equivalent to `f(i, args...)` if `parallelize` is `true` and `for (decltype(shape) i=0; i<shape; i++) { f(i, shape, args...) }` otherwise; and
          - [11.2.1.2.2]{.pnum} `s` is a preallocated backend storage for `r`.

    - [11.2.2]{.pnum} All other completion operations are forwarded unchanged.


:::

<hr>

In section `query_parallel_scheduler_backend` [exec.sysctxrepl.query], apply the following changes:

```cpp
namespace std::execution::system_context_replaceability {
  struct receiver_proxy {
    @[`virtual ~receiver_proxy() = default;`]{.rm}@

  protected:
    virtual bool @_query-env_@(@_unspecified_@) noexcept = 0;   // exposition only

  public:
    virtual void set_value() noexcept = 0;
    virtual void set_error(exception_ptr) noexcept = 0;
    virtual void set_stopped() noexcept = 0;

    template<class P, @_class-type_@ Query>
      optional<P> try_query(Query q) @[`const`]{.add}@ noexcept;
  };

  struct bulk_item_receiver_proxy : receiver_proxy {
    virtual void execute(size_t, size_t) noexcept = 0;
  };
}
```

[4]{.pnum} `receiver_proxy` represents a receiver that will be notified by the implementations of `parallel_scheduler_backend` to trigger the completion operations. `bulk_item_receiver_proxy` is derived from `receiver_proxy` and is used for `bulk_chunked` and `bulk_unchunked` customizations that will also receive notifications from implementations of `parallel_scheduler_backend` corresponding to different iterations.

```cpp
template <class P, @_class-type_@ Query>
optional<P> try_query(Query q) @[`const`]{.add}@ noexcept;
```

[5]{.pnum} *Mandates*: `P` is a cv-unqualified non-array object type.

[6]{.pnum} *Returns*: Let `env` be the environment of the receiver represented by `*this`[ and `template <typename T, typename R> R` _implementation-defined-transform_`(T&&)` an implementation-defined transformation]{.add}.
If:

- [6.1]{.pnum} `Query` is not a member of an implementation-defined set of supported queries; or
- [6.2]{.pnum} `P` is not a member of an implementation-defined set of supported result types for `Query`; or
- [6.3]{.pnum} the expression `q(env)` is not well-formed[; or]{.add}[ or does not have type _`cv`_ `P`,]{.rm}
- [[6.4]{.pnum} the expression _implementation-defined-transform_`(q(env))` is not well-formed or does not have type _`cv`_ `P`,]{.add}

then returns `nullopt`. Otherwise, returns `q(env)`.

[7]{.pnum} *Remarks*: `get_stop_token_t` is in the implementation-defined set of supported queries, and `inplace_stop_token` is a member of the implementation-defined set of supported result types for `get_stop_token_t`.

[[8]{.pnum} *Recommended practice*: `template <typename T> inplace_stop_token` _implementation-defined-transform_`(T&&)` should be defined for any `T` that models `stoppable_token`]{.add}

# Acknowledgments #

Thanks to Tim Song and Tomasz KamiÅ„ski for working extra time to ensure that [@P2079R10] is specified with high standards. The C++ standard would not have been at the same level of quality without their love and care.

Thanks to Lewis Baker for constantly pushing to get better and better solutions to the problems at hand.
