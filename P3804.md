---
title: Iterating on `parallel_scheduler`
document: P3804R0
date: today
author:
    - name: Lucian Radu Teodorescu (Garmin)
      email: <lucteo@lucteo.ro>
    - name: Ruslan Arutyunyan (Intel)
      email: <ruslan.arutyunyan@intel.com>
audience:
    - SG1, LEWG
---

<style>
@media screen {
    #TOC {
        position: fixed;
        width: min(25%, 30em);
        height: 100%;
        left: 0;
        top: 0;
        overflow-y: scroll;
        padding-left: 1em;
        padding-right: 1em;
        text-align: left;
        a {
            font-size: 100%;
        }
    }
    body {
        padding-left: min(26%, 32em);
    }
}
</style>

# Abstract # {- .unlisted}

Although `parallel_scheduler` [@P2079R10] had a long time in the baking, getting it adopted in Sofia 2025 still left the impression that some of the fine details were not sufficiently discussed. This paper proposes to iterate over some of these aspects, aiming at getting the best possible outcome from `parallel_scheduler`.

# Introduction #

This paper tries to address the following concerns:

* Minor design tweaks:
  1. `receiver_proxy::try_query` could possibly be const-qualified.
  2. `receiver_proxy` does not need a virtual destructor as the object is never destroyed polymorphically.
  3. `receiver_proxy::try_query` requires `inplace_stop_token` and doesn't accept an arbitrary stop token.
  4. The list of properties supported by `receiver_proxy::try_query` is implementation-defined.
* Design concerns with larger impact:
  5. `receiver_proxy::try_query` currently requires the list of supported queries to be defined.
* Naming:
  6. `system_context_replaceability` is not a good name to use for the namespace in which the replaceability APIs lie.
* Wording:
  7. The wording around a customizations of `bulk_unchunked`/`bulk_chunked` for `parallel_scheduler` isn't precise enough.
* Interactions with other NB comments:
  8. Removing customization mechanisms

# Discussions #

## `receiver_proxy::try_query` could possibly be const-qualified

Currently the specification defines `try_query` as:
```cpp
template<class P, @_class-type_@ Query>
optional<P> try_query(Query q) noexcept;
```

This is not marked as `const`, but there is no good reason why we couldn't mark it as such.
This paper proposes a change to mark this function as `const`.

## `receiver_proxy` does not need a virtual destructor

The code that destroys instances of `receiver_proxy` knows the actual type of the object, so the objects of type `receiver_proxy` don't need to be polymorphically destroyed.
This paper proposes to remove the virtual destructor.

## `receiver_proxy::try_query` requires `inplace_stop_token` and doesn’t accept an arbitrary stop token

The specification of `parallel_scheduler::try_query` [@P2079R10] is too restrictive with respect to querying stop tokens.
The wording states ([exec.sysctxrepl.query]):

---

```cpp
template <class P, @_class-type_@ Query>
optional<P> try_query(Query q) noexcept;
```

[5]{.pnum} *Mandates*: `P` is a cv-unqualified non-array object type.

[6]{.pnum} *Returns*: Let `env` be the environment of the receiver represented by `*this`.
If:

- [6.1]{.pnum} `Query` is not a member of an implementation-defined set of supported queries; or
- [6.2]{.pnum} `P` is not a member of an implementation-defined set of supported result types for `Query`; or
- [6.3]{.pnum} the expression `q(env)` is not well-formed or does not have type _`cv`_ `P`,

then returns `nullopt`. Otherwise, returns `q(env)`.

[7]{.pnum} *Remarks*: `get_stop_token_t` is in the implementation-defined set of supported queries, and `inplace_stop_token` is a member of the implementation-defined set of supported result types for `get_stop_token_t`.

---

This implies that, if `q(get_stop_token_t)` returns `std::stop_token`, then `try_query(get_stop_token_t)` returns `nullopt`.
More generally, if `q(get_stop_token_t)` returns a type that models `stoppable_token`, other than `inplace_stop_token`, then `try_query(get_stop_token_t)` returns `nullopt`.
There is no portable way for the backend to check the stop token of the receiver.

This paper proposes an extension of the above schema to allow the possibility of using stop tokens other than `inplace_stop_token`.
If `q(env)` has the type _`cv`_  `T`, and there is an implementation defined mapping from objects of type `T` to objects of type `P`, then `try_query<P>(q)` is allowed to return non-null objects.

We recommend the implementations to support such mappings between any stop token to `inplace_stop_token`.
This would essentially make the frontend register a stop callback to the token from the environment and transform the stop request into a stop request to a temporary `inplace_stop_token`.

Please note that this mechanism is useful for other property types, not just stop tokens.

We also considered an alternative design in which we add a `request_stop` member-function to `parallel_scheduler_backend`.
This method would increase the API surface, and render the property-querying mechanism useless.
We considered this solution to be less flexible, as, on the long run, it would lead to an overly-complex API for replaceability.

The variant that adds the `request_stop` function to `parallel_scheduler_backend` tends to require less storage in the backend.
If the backend wants to stop the process of acquiring an execution agent, it typically needs to register a stop callback that is able to stop the process.
This requires an extra storage in the backend.

This alternative requires always registering a stop callback in the frontend, but no stop callback in the backend.
The current proposal would (almost) always require a stop callback in the backend, and, might require a stop callback in the frontend too, if we need to adapt a generic stop token into an `inplace_stop_token`.

## The list of properties supported by `receiver_proxy::try_query` is implementation-defined

When [@P2079R10] defines the possibilities for the backend to query the properties of the final receiver it specifies that the list of properties (both property types and query types) are implementation-defined.
Instead, the proposal could have defined a fixed list of properties to be supported when replacing the backend.

That seems to be a limiting factor as we would want to support two use-cases:

1. Implementers might want to add additional properties to be queried
1. Implementers might not want to implement all the properties

A good example for the first case is a vendor adding support for thread priorities.
With the existing proposal, this can be done in a compliant manner.

The second case involves implementors opting out of certain properties.
Let us assume that we standardize a mechanism to query thread priorities from the receiver.
But, this may not make much difference on certain platforms, thus the implementors shall be able to opt out of supporting this query.
Supporting a query typically has a small cost associated with it, so it makes sense to allow opting out of this cost if it doesn't make sense for the targeted platform.

Even with stop token property that is specified by [@P2079R10], it may not always make sense to support cancellation on the backend.
The frontend can implement cancellation without passing this information to the backend.

If we keep the list of properties (and query types) to be implementation-defined and fixed, we can always relax this later.
Relaxing this in a later standard will imply that we would need to support new properties; this would be similar to adding new properties to be supported.

Thus, the authors believe that the current option of making the list of properties (and query types) is the right choice for the users and no changes are needed here.

## `receiver_proxy::try_query` currently requires the list of supported queries to be defined

One workflow that some of C++ have is to have separate compilations of their libraries.
Two libraries, A and B can be compiled separately, sometimes with different versions of the compiler, sometimes even with different compilers (provided that the ABI match).
This feature cannot break this flow.

For practical reasons, we can consider the backend of `parallel_scheduler` as yet another library C that can be compiled separately from the rest of the program.
The backend may be compiled with different flag and with a different compiler than the rest of the libraries (again, if the ABI matches).
That is, there is a complete separation between the frontend (library implementing `parallel_scheduler`) and the backend (user provided implementation of `parallel_scheduler_backend`).
Things are more complicated as the user code (the environment of the receiver connected to a `parallel_scheduler` sender) is outside of the control of the standard library.

Thus, we have 3 components that we need to align:

* user code (receiver's environment),
* frontend (`parallel_scheduler` implementation in the standard library),
* backend (user supplied functionality for launching execution agents).

One attempt of trying to bridge these three things might look like:

```cpp
// backend code
struct receiver_proxy {
  template<typename R, typename Q>
  std::optional<R> try_query(Q) {
    alignas(R) std::byte storage[sizeof(R)];
    if (try_query_impl(typeid(Q), typeid(R), &storage)) {
       struct dtor {
          R& result;
          ~dtor() { result.~R(); }
       };
       dtor d{*std::launder(reinterpret_cast<R*>(&storage))};
       return std::move(d.result);
    }
    return std::nullopt;
  }
private:
   virtual bool try_query_impl(std::type_index query_id, std::type_index result_id, void* result_addr) = 0;
};

// frontend code
template<typename Receiver>
struct receiver_proxy_impl : receiver_proxy {
   using env_t = std::env_of_t<Receiver>;
   using queries_t = queries_of_t<env_t>;
   template<typename Q>
   using query_result_t = decltype(auto(std::declval<const env_t&>().query(Q{})));

   Receiver rcvr;

   struct vtable_entry {
     std::type_index query_id;
     std::type_index result_id;
     void (*getter)(receiver_proxy*, void* address);
   };

   template<typename... Queries>
   static constexpr auto make_query_vtable(type_list<Queries...>) {
      return std::array<vtable_entry, sizeof...(Queries)> vtable{
        {typeid(Queries),
         typeid(query_result_t<Queries>),
         [](receiver_proxy* proxy, void* address) {
           ::new (address) query_result_t<Queries>(get_env(static_cast<receiver_proxy_impl*>(proxy)->receiver).query(Queries{}));
         }}...};
   }

   bool try_query_impl(std::type_index query_id,
                       std::type_index result_id,
                       void* address) {
     static constexpr auto vtable = make_query_vtable(queries_t{});
     for (auto& entry : vtable) {
       if (entry.query_id == query_id && entry.result_id == result_id) {
         entry.getter(this, address);
         return true;
       }
     }
     return false;
   }

   // ... etc. for set_value, and other methods
};
```

The key for this implementation is the `make_query_vtable` function in the frontend that makes a vtable-like structure containing ways to access the properties of the receiver's environment.
But this requires that the frontend has access, at compile-time, to the list of properties that the receiver supports.
In our example, this is represented by `queries_of_t<env_t>`, which is not detailed here.

The problem is that we don't have yet a good way to implement this query.
To fully support all the properties that the receiver has, the frontend needs to be able to build them into a type list.
We don't have support for this.

Without such a facility, the frontend and the backend can only query a set of properties that it knows.
This aligns with the direction proposed by [@P2079R10].

If we would find such a solution in the future, the frontend can support new properties, which could be picked by the backend.
As this is a relaxation of constraints, future standards can do it without breaking changes.

The authors don't see any changes in this area that would benefit the users in a tangible way.

## `system_context_replaceability` is not a good name to use for the namespace in which the replaceability APIs lie

Previously, `parallel_scheduler` was called `system_scheduler`, and was part of `system_context`.
In that sense, the name `system_context_replaceability` made sense; it was the namespace in which we put things related to replacing default implementation around `system_context`.
But now, we ended up with a different name, so the question is whether `system_context_replaceability` still makes sense.

There are people who's answer would be no.
In that case, we might rename the namespace to something like `parallel_scheduler_replaceability`.

But, there are also arguments for keeping the current name.
We also envision having different types of schedulers.
We were previously taking about a `main_scheduler` to be used on systems that have only one thread, or in which the main thread needs special treatment.
We also had brief discussions about the need of `io_scheduler` (or `elastic_parallel_scheduler`) and `priority_scheduler` (to create threads with different priorities).

There is a high chance that we would add new system-wide schedulers in the future.
But, if that is the case, and we want their backends to be replaceable, should we create completely different namespaces for them?
Or should we reuse the abstractions that we already have?

Probably, a good answer would be that we want to reuse the same namespace.
In this context, the name `system_context_replaceability` makes sense.
Especially since the work `context` appears in the name, not the word `scheduler`.

The authors don't have a strong preference, and would like this to be discussed in LEWG.
The following table shows a few options:

| Proposal | Notes            |
| -------- | ---------------- |
| `system_context_replaceability` | Status quo. Allows replacing other backend in the future |
| `parallel_scheduler_replaceability` | Better matches the new name |
| `scheduler_replaceability` | Variation |
| `scheduler_backend_replaceability` | Variation |
| `parallel_scheduler_backend_replaceability` | Variation |
| `replacement` | Simpler name; can be extended in the future |
| `replacement_functions` | Variation; problematic the use of `functions` |
| `psr` | Shorter name from `parallel_scheduler_replaceability` |
| `scr` | Shorter name from `system_context_replaceability` |

## The wording around a customizations of `bulk_unchunked`/`bulk_chunked` for `parallel_scheduler` isn’t precise enough

The wording in [@P2079R10] mandated that we want customizations for `bulk_unchunked`/`bulk_chunked`, but it did not describe the details.
Actually, this discussion was completely missing from the design section too.
The proof of concept implementation used the early customization mechanism, and part of the authors assumed that was always the case, but the paper doesn't mention anything about it.
This needs to be fixed.

Also, the customization part does not treat the execution policy at all.
Again, this needs to be fixed.

[@D3826] proposes to defer adding customizations to a later standard, and proposes a solution for allowing `parallel_scheduler` to customize the behavior of `bulk_chunked` and `bulk_unchunked`.
We aim at building on top of [@D3826].


## Removing customization mechanisms

Eric Niebler announced on reflector that NVIDA adds an NB comment suggesting to remove customization mechanisms from senders/receivers from C++26, and adding it into future versions of the standard.
This was translated into  [@D3826].
If that change is to be adopted, it also has implications to `parallel_scheduler`.
We explore here the implications.

Although originally the thought was to completely remove customizations, after discussions the consensus was for  [@D3826] to move towards a model that allows controlled customizations.
This would allow vendors to provide customizations of `bulk` for `parallel_scheduler`.
But, this mechanism is not widely exposed to the users.

This paper builds upon the effort in [@D3826].

# Proposed wording #

[In section _Parallel scheduler_ [exec.par.scheduler], apply the following changes:]{.ednote}

::: rm

[7]{.pnum} A _bulk chunked proxy for `rcvr` with callable `f` and arguments `args`_ is a proxy `r` for `rcvr` with base `system_context_replaceability::bulk_item_receiver_proxy` such that`r.execute(i, j)` for indices `i` and `j` has effects equivalent to `f(i, j, args...)`.

[8]{.pnum} A _bulk unchunked proxy for `rcvr` with callable `f` and arguments `args`_ is a proxy `r` for `rcvr` with base `system_context_replaceability::bulk_item_receiver_proxy` such that `r.execute(i, i+1)` for index `i` has effects equivalent to `f(i, args...)`.

:::

[9]{.pnum} Let `b` be <i>`BACKEND-OF`</i>`(sch)`, let `sndr` be the object returned by `schedule(sch)`, and let `rcvr` be a receiver.
  If `rcvr` is connected to `sndr` and the resulting operation state is started, then:
    - If `sndr` completes successfully, then `b.schedule(r, s)` is called, where:
      - `r` is a proxy for `rcvr` with base `system_context_replaceability::receiver_proxy`; and
      - `s` is a preallocated backend storage for `r`.
  - All other completion operations are forwarded unchanged.

[Also contains the changes from D3826:]{.ednote}

::: add

[?]{.pnum} Let `sch` be a subexpression of type `parallel_scheduler`.
For subexpressions `sndr` and `env`, if `tag_of_t<Sndr>` is neither `bulk_chunked_t` nor `bulk_unchunked_t`, the expression `sch.@_bulk-transform_@(sndr, env)` is ill-formed; otherwise, let `child`, `pol`, `shape`, and `f` be subexpressions equal to the arguments used to create `sndr`.
Also, let _`parallelizable`_ be `true` if `pol` is `par` or `par_unseq`, and `false` otherwise.

:::

[10]{.pnum} [`parallel_scheduler` provides a customized implementation of `bulk_chunked` algorithm ([exec.bulk]{.sref}).
  If a receiver `rcvr` is connected to the sender returned by `bulk_chunked(sndr, pol, shape, f)`]{.rm}[When the tag type of `sndr` is `bulk_chunked_t`, the expression `sch.@_bulk-transform_@(sndr, env)` returns a sender `new_sndr` such that if it is connected to a receiver `rcvr`]{.add} and the resulting operation state is started, then:

- [10.1]{.pnum} If [`sndr`]{.rm} [`child`]{.add} completes with values `vals`, let `args` be a pack of lvalue subexpressions designating `vals`, then `b.schedule_bulk_chunked(@[shape]{.rm} [parallelize ? shape : 1]{.add}@, r, s)` is called, where:
  - [10.1.1]{.pnum} [`r` is a bulk chunked proxy for `rcvr` with callable `f` and arguments `args`; and]{.rm}
  - [10.1.1]{.pnum} [`r` is a proxy for `rcvr` with base `system_context_replaceability::bulk_item_receiver_proxy` such that `r.execute(i, j)` for indices `i` and `j` has effects equivalent to `f(i, j, args...)` if `parallelize` is `true` and `f(0, shape, args...)` otherwise; and]{.add}
  - [10.1.2]{.pnum} `s` is a preallocated backend storage for `r`.
- [10.2]{.pnum} All other completion operations are forwarded unchanged.

[[Customizing the behavior of `bulk_chunked` affects the default implementation of `bulk`]{.note}.]{.rm}

[11]{.pnum} [`parallel_scheduler` provides a customized implementation of `bulk_unchunked` algorithm ([exec.bulk]{.sref}).
  If a receiver `rcvr` is connected to the sender returned by `bulk_unchunked(sndr, pol, shape, f)`]{.rm}[When the tag type of `sndr` is `bulk_unchunked_t`, the expression `sch.@_bulk-transform_@(sndr, env)` returns a sender `new_sndr` such that if it is connected to a receiver `rcvr`]{.add} and the resulting operation state is started, then:

- [11.1]{.pnum} If [`sndr`]{.rm} [`child`]{.add} completes with values `vals`, let `args` be a pack of lvalue subexpressions designating `vals`, then `b.schedule_bulk_unchunked(shape, r, s)` is called, where:
  - [11.1.1]{.pnum} [`r` is a bulk unchunked proxy for `rcvr` with callable `f` and arguments `args`; and]{.rm}
  - [10.1.1]{.pnum} [`r` is a proxy for `rcvr` with base `system_context_replaceability::bulk_item_receiver_proxy` such that `r.execute(i, i+1)` for index `i` has effects equivalent to `f(i, args...)` if `parallelize` is `true` and `for (decltype(shape) i=0; i<shape; i++) { f(i, args...); }` otherwise; and]{.add}
  - [11.1.2]{.pnum} `s` is a preallocated backend storage for `r`.
- [11.2]{.pnum} All other completion operations are forwarded unchanged.


<hr>

[In section _`query_parallel_scheduler_backend`_ [exec.sysctxrepl.query], apply the following changes:]{.ednote}

```cpp
namespace std::execution::system_context_replaceability {
  struct receiver_proxy {
    @[`virtual ~receiver_proxy() = default;`]{.rm}@

  protected:
    virtual bool @_query-env_@(@_unspecified_@) noexcept = 0;   // exposition only

  public:
    virtual void set_value() noexcept = 0;
    virtual void set_error(exception_ptr) noexcept = 0;
    virtual void set_stopped() noexcept = 0;

    template<class P, @_class-type_@ Query>
      optional<P> try_query(Query q) @[`const`]{.add}@ noexcept;
  };

  struct bulk_item_receiver_proxy : receiver_proxy {
    virtual void execute(size_t, size_t) noexcept = 0;
  };
}
```

[4]{.pnum} `receiver_proxy` represents a receiver that will be notified by the implementations of `parallel_scheduler_backend` to trigger the completion operations. `bulk_item_receiver_proxy` is derived from `receiver_proxy` and is used for `bulk_chunked` and `bulk_unchunked` customizations that will also receive notifications from implementations of `parallel_scheduler_backend` corresponding to different iterations.

```cpp
template <class P, @_class-type_@ Query>
optional<P> try_query(Query q) @[`const`]{.add}@ noexcept;
```

[5]{.pnum} *Mandates*: `P` is a cv-unqualified non-array object type.

[6]{.pnum} *Returns*: Let `env` be the environment of the receiver represented by `*this` [ and `template <typename T, typename R> R` _`implementation-defined-transform`_`(T&&)` an implementation-defined transformation]{.add}.
If:

- [6.1]{.pnum} `Query` is not a member of an implementation-defined set of supported queries; or
- [6.2]{.pnum} `P` is not a member of an implementation-defined set of supported result types for `Query`; or
- [6.3]{.pnum} the expression `q(env)` is not well-formed[; or]{.add}[ or does not have type _`cv`_ `P`,]{.rm}
- [[6.4]{.pnum} the expression _`implementation-defined-transform`_`(q(env))` is not well-formed or does not have type _`cv`_ `P`,]{.add}

then returns `nullopt`. Otherwise, returns `q(env)`.

[7]{.pnum} *Remarks*: `get_stop_token_t` is in the implementation-defined set of supported queries, and `inplace_stop_token` is a member of the implementation-defined set of supported result types for `get_stop_token_t`.

[[8]{.pnum} *Recommended practice*: `template <typename T> inplace_stop_token` _`implementation-defined-transform`_`(T&&)` should be defined for any `T` that models `stoppable_token`]{.add}

# Acknowledgments #

Thanks to Tim Song and Tomasz Kamiński for working extra time to ensure that [@P2079R10] is specified with high standards. The C++ standard would not have been at the same level of quality without their love and care.

Thanks to Lewis Baker for constantly pushing to get better and better solutions to the problems at hand.
